{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-13T08:39:00.341809Z",
     "iopub.status.busy": "2025-04-13T08:39:00.341515Z",
     "iopub.status.idle": "2025-04-13T08:39:00.603289Z",
     "shell.execute_reply": "2025-04-13T08:39:00.602579Z",
     "shell.execute_reply.started": "2025-04-13T08:39:00.341788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Dataset (Roman Urdu Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:48:19.588580Z",
     "iopub.status.busy": "2025-04-12T18:48:19.588206Z",
     "iopub.status.idle": "2025-04-12T18:48:19.597824Z",
     "shell.execute_reply": "2025-04-12T18:48:19.597198Z",
     "shell.execute_reply.started": "2025-04-12T18:48:19.588549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cleaner(word):\n",
    "    word = re.sub(r'\\#\\.', '', word)\n",
    "    word = re.sub(r'\\n', '', word)\n",
    "    word = re.sub(r',', '', word)\n",
    "    word = re.sub(r'\\-', ' ', word)\n",
    "    word = re.sub(r'\\.', '', word)\n",
    "    word = re.sub(r'\\\\', ' ', word)\n",
    "    word = re.sub(r'\\\\x\\.+', '', word)\n",
    "    word = re.sub(r'\\d', '', word)\n",
    "    word = re.sub(r'^_.', '', word)\n",
    "    word = re.sub(r'_', ' ', word)\n",
    "    word = re.sub(r'^ ', '', word)\n",
    "    word = re.sub(r' $', '', word)\n",
    "    word = re.sub(r'\\?', '', word)\n",
    "    return word.lower()\n",
    "\n",
    "# Define the hashing function\n",
    "def hashing(word):\n",
    "    word = re.sub(r'ain$', r'ein', word)\n",
    "    word = re.sub(r'ai', r'ae', word)\n",
    "    word = re.sub(r'ay$', r'e', word)\n",
    "    word = re.sub(r'ey$', r'e', word)\n",
    "    word = re.sub(r'ie$', r'y', word)\n",
    "    word = re.sub(r'^es', r'is', word)\n",
    "    word = re.sub(r'a+', r'a', word)\n",
    "    word = re.sub(r'j+', r'j', word)\n",
    "    word = re.sub(r'd+', r'd', word)\n",
    "    word = re.sub(r'u', r'o', word)\n",
    "    word = re.sub(r'o+', r'o', word)\n",
    "    word = re.sub(r'ee+', r'i', word)\n",
    "    if not re.match(r'ar', word):\n",
    "        word = re.sub(r'ar', r'r', word)\n",
    "    word = re.sub(r'iy+', r'i', word)\n",
    "    word = re.sub(r'ih+', r'eh', word)\n",
    "    word = re.sub(r's+', r's', word)\n",
    "    if re.search(r'[rst]y', word) and word[-1] != 'y':\n",
    "        word = re.sub(r'y', r'i', word)\n",
    "    if re.search(r'[bcdefghijklmnopqrtuvwxyz]i', word):\n",
    "        word = re.sub(r'i$', r'y', word)\n",
    "    if re.search(r'[acefghijlmnoqrstuvwxyz]h', word):\n",
    "        word = re.sub(r'h', '', word)\n",
    "    word = re.sub(r'k', r'q', word)\n",
    "    return word\n",
    "\n",
    "# Clean the text data\n",
    "def array_cleaner(array):\n",
    "    X = []\n",
    "    for sentence in array:\n",
    "        clean_sentence = ''\n",
    "        words = str(sentence).split(' ')\n",
    "        for word in words:\n",
    "            clean_sentence = clean_sentence + ' ' + cleaner(word)\n",
    "        X.append(clean_sentence)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:45.686484Z",
     "iopub.status.busy": "2025-04-12T04:00:45.686227Z",
     "iopub.status.idle": "2025-04-12T04:00:45.802332Z",
     "shell.execute_reply": "2025-04-12T04:00:45.801753Z",
     "shell.execute_reply.started": "2025-04-12T04:00:45.686464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wah kya baat likhi</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Text Sentiment\n",
       "0             sahi bt h  Positive\n",
       "1           Kya bt hai,  Positive\n",
       "2            Wah je wah  Positive\n",
       "3  Are wha kaya bat hai  Positive\n",
       "4    Wah kya baat likhi  Positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset (replace with your actual dataset)\n",
    "data = pd.read_csv('/kaggle/input/sentiment-dataset/Roman Urdu DataSet.csv')  # Replace with your actual CSV path\n",
    "# Manually assign column names\n",
    "data.columns = ['Text', 'Sentiment', 'extra']\n",
    "data = data.iloc[:,0:2]\n",
    "# Check the first few rows to confirm\n",
    "data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:46.764111Z",
     "iopub.status.busy": "2025-04-12T04:00:46.763804Z",
     "iopub.status.idle": "2025-04-12T04:00:48.682826Z",
     "shell.execute_reply": "2025-04-12T04:00:48.682263Z",
     "shell.execute_reply.started": "2025-04-12T04:00:46.764090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_cleaned = array_cleaner(data['Text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:49.795187Z",
     "iopub.status.busy": "2025-04-12T04:00:49.794914Z",
     "iopub.status.idle": "2025-04-12T04:00:49.805726Z",
     "shell.execute_reply": "2025-04-12T04:00:49.804983Z",
     "shell.execute_reply.started": "2025-04-12T04:00:49.795166Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kya bt hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wah kya baat likhi</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text     label\n",
       "0              sahi bt h  Positive\n",
       "1             kya bt hai  Positive\n",
       "2             wah je wah  Positive\n",
       "3   are wha kaya bat hai  Positive\n",
       "4     wah kya baat likhi  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': X_cleaned,  # Cleaned text data\n",
    "    'label': data['Sentiment']  # Sentiment labels\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:51.291099Z",
     "iopub.status.busy": "2025-04-12T04:00:51.290408Z",
     "iopub.status.idle": "2025-04-12T04:00:51.302862Z",
     "shell.execute_reply": "2025-04-12T04:00:51.302169Z",
     "shell.execute_reply.started": "2025-04-12T04:00:51.291075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Neutral     8929\n",
       "Positive    6012\n",
       "Negative    5286\n",
       "Neative        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:52.972741Z",
     "iopub.status.busy": "2025-04-12T04:00:52.972507Z",
     "iopub.status.idle": "2025-04-12T04:00:52.987733Z",
     "shell.execute_reply": "2025-04-12T04:00:52.987140Z",
     "shell.execute_reply.started": "2025-04-12T04:00:52.972724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Neutral     8929\n",
       "Positive    6012\n",
       "Negative    5286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['label'] != 'Neative']\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:00:56.197564Z",
     "iopub.status.busy": "2025-04-12T04:00:56.197276Z",
     "iopub.status.idle": "2025-04-12T04:00:56.715243Z",
     "shell.execute_reply": "2025-04-12T04:00:56.714688Z",
     "shell.execute_reply.started": "2025-04-12T04:00:56.197543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 as Neutrel, 2 as positive, 0 as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:01:14.025905Z",
     "iopub.status.busy": "2025-04-12T04:01:14.025242Z",
     "iopub.status.idle": "2025-04-12T04:01:14.034814Z",
     "shell.execute_reply": "2025-04-12T04:01:14.034210Z",
     "shell.execute_reply.started": "2025-04-12T04:01:14.025885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    8929\n",
       "2    6012\n",
       "0    5286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now Fine tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First we will use auto-tokenizer class from transformer library. it will read the description from config file of model (i.e our model type: albert)\n",
    "2) so it will use albert tokenizer for this model\n",
    "3) then we will convert our df in hugging face compatible dataset\n",
    "4) then we will tokenize our dataset according to the model in which max lenght is 128 it means there will be 128 tokens for each input.\n",
    "5) then splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"callmesan/indic-bert-roman-urdu-fine-grained\")\n",
    "\n",
    "# Convert your pandas DataFrame to a HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize the text column of the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Split the dataset into training and test sets (80% train, 20% test)\n",
    "train_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(0, int(0.8 * len(tokenized_datasets)))])  # 80% train\n",
    "test_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(int(0.8 * len(tokenized_datasets)), len(tokenized_datasets))])  # 20% test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Now i red in the config file that there are 5 labels in the model but we have only 3 labels in our dataset so we reset the number of labels to 3\n",
    "2) it is using albert for sequence classification cos our model is based on albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:06:19.500827Z",
     "iopub.status.busy": "2025-04-12T04:06:19.500242Z",
     "iopub.status.idle": "2025-04-12T04:06:19.620151Z",
     "shell.execute_reply": "2025-04-12T04:06:19.619600Z",
     "shell.execute_reply.started": "2025-04-12T04:06:19.500806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at callmesan/indic-bert-roman-urdu-fine-grained and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# Load the config and set num_labels=3\n",
    "config = AutoConfig.from_pretrained(\n",
    "    'callmesan/indic-bert-roman-urdu-fine-grained',\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "# Load model with the modified config and ignore mismatches\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'callmesan/indic-bert-roman-urdu-fine-grained',\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True  # this tells Transformers to ignore the old classification head\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Check where the model is\n",
    "print(\"Model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the training arguments in which \n",
    "epochs are 10 means the dataset will be pass 10 times through model\n",
    "batch size is 16 means the model will take 16 sentences at once as input for learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:31:02.416079Z",
     "iopub.status.busy": "2025-04-12T05:31:02.415779Z",
     "iopub.status.idle": "2025-04-12T05:31:02.459343Z",
     "shell.execute_reply": "2025-04-12T05:31:02.458639Z",
     "shell.execute_reply.started": "2025-04-12T05:31:02.416058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=10,              # number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",     # evaluation strategy to adopt during training\n",
    "    save_strategy=\"epoch\",           # save checkpoint every epoch\n",
    "    report_to=\"all\",  # Show both console and progress bar\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    disable_tqdm=False  # Ensure progress bars are visible\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the model to train\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:06:25.209597Z",
     "iopub.status.busy": "2025-04-12T04:06:25.208838Z",
     "iopub.status.idle": "2025-04-12T04:39:41.085653Z",
     "shell.execute_reply": "2025-04-12T04:39:41.085051Z",
     "shell.execute_reply.started": "2025-04-12T04:06:25.209573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5060' max='5060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5060/5060 33:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.967400</td>\n",
       "      <td>0.981294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.925810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.837916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.820168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.940775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>1.101908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>1.395361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>1.829128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>2.009142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>2.109982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5060, training_loss=0.45969014363437005, metrics={'train_runtime': 1995.3972, 'train_samples_per_second': 81.092, 'train_steps_per_second': 2.536, 'total_flos': 966833525137920.0, 'train_loss': 0.45969014363437005, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:10:06.303345Z",
     "iopub.status.busy": "2025-04-12T05:10:06.302800Z",
     "iopub.status.idle": "2025-04-12T05:10:07.044148Z",
     "shell.execute_reply": "2025-04-12T05:10:07.043334Z",
     "shell.execute_reply.started": "2025-04-12T05:10:06.303324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"./results/checkpoint-4554\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"callmesan/indic-bert-roman-urdu-fine-grained\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:10:07.953256Z",
     "iopub.status.busy": "2025-04-12T05:10:07.952688Z",
     "iopub.status.idle": "2025-04-12T05:10:08.244569Z",
     "shell.execute_reply": "2025-04-12T05:10:08.243982Z",
     "shell.execute_reply.started": "2025-04-12T05:10:07.953235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:10:09.294306Z",
     "iopub.status.busy": "2025-04-12T05:10:09.294057Z",
     "iopub.status.idle": "2025-04-12T05:10:09.302076Z",
     "shell.execute_reply": "2025-04-12T05:10:09.301376Z",
     "shell.execute_reply.started": "2025-04-12T05:10:09.294289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'LABEL_0': 'Negative',\n",
    "    'LABEL_1': 'Neutral',\n",
    "    'LABEL_2': 'Positive'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:28:22.632519Z",
     "iopub.status.busy": "2025-04-12T05:28:22.631749Z",
     "iopub.status.idle": "2025-04-12T05:28:22.652053Z",
     "shell.execute_reply": "2025-04-12T05:28:22.651103Z",
     "shell.execute_reply.started": "2025-04-12T05:28:22.632489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: tum kitne pyare ho\n",
      "Predicted Sentiment: Negative (0.90)\n"
     ]
    }
   ],
   "source": [
    "# Pretty print result\n",
    "text = \"tum kitne pyare ho\"\n",
    "result = classifier(text)[0]\n",
    "label_name = label_map[result['label']]\n",
    "score = result['score']\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Predicted Sentiment: {label_name} ({score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now again fine tuning on a new dataset (review 1 cleaned.csv)\n",
    "i already cleaned it on google collab (Review 1 cleaning in google colab using svm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:49:15.354008Z",
     "iopub.status.busy": "2025-04-12T18:49:15.353480Z",
     "iopub.status.idle": "2025-04-12T18:49:15.502701Z",
     "shell.execute_reply": "2025-04-12T18:49:15.502042Z",
     "shell.execute_reply.started": "2025-04-12T18:49:15.353981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allah nahi usko bachana tha to us road sy hi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apnay bhai ki madad karo qatil</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bohot ghandi choice hai teri qatil</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kis kis ko pakistan buhat pasand hai        ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibrahim ki mama qatil ki bohot achi acting d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0    allah nahi usko bachana tha to us road sy hi...  negative\n",
       "1                    apnay bhai ki madad karo qatil   positive\n",
       "2                bohot ghandi choice hai teri qatil   negative\n",
       "3    kis kis ko pakistan buhat pasand hai        ...  positive\n",
       "4    ibrahim ki mama qatil ki bohot achi acting d...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('/kaggle/input/sentiment-dataset-2/review 1 cleaned.csv', encoding='ISO-8859-1')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:49:17.038694Z",
     "iopub.status.busy": "2025-04-12T18:49:17.038373Z",
     "iopub.status.idle": "2025-04-12T18:49:17.064312Z",
     "shell.execute_reply": "2025-04-12T18:49:17.063451Z",
     "shell.execute_reply.started": "2025-04-12T18:49:17.038672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    10331\n",
       "negative     9437\n",
       "neutral      8321\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:49:17.945506Z",
     "iopub.status.busy": "2025-04-12T18:49:17.944887Z",
     "iopub.status.idle": "2025-04-12T18:49:18.508113Z",
     "shell.execute_reply": "2025-04-12T18:49:18.507595Z",
     "shell.execute_reply.started": "2025-04-12T18:49:17.945482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Encode string labels to numeric\n",
    "le = LabelEncoder()\n",
    "df2['label'] = le.fit_transform(df2['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 as Neutrel, 2 as positive, 0 as negative (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:49:21.211869Z",
     "iopub.status.busy": "2025-04-12T18:49:21.211476Z",
     "iopub.status.idle": "2025-04-12T18:49:21.227163Z",
     "shell.execute_reply": "2025-04-12T18:49:21.226501Z",
     "shell.execute_reply.started": "2025-04-12T18:49:21.211846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    10331\n",
       "0     9437\n",
       "1     8321\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now again all training steps are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"callmesan/indic-bert-roman-urdu-fine-grained\")\n",
    "\n",
    "# Convert your pandas DataFrame to a HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df2)\n",
    "\n",
    "# Tokenize the text column of the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Split the dataset into training and test sets (80% train, 20% test)\n",
    "train_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(0, int(0.8 * len(tokenized_datasets)))])  # 80% train\n",
    "test_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(int(0.8 * len(tokenized_datasets)), len(tokenized_datasets))])  # 20% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:01.521609Z",
     "iopub.status.busy": "2025-04-12T18:50:01.521299Z",
     "iopub.status.idle": "2025-04-12T18:50:28.907541Z",
     "shell.execute_reply": "2025-04-12T18:50:28.906604Z",
     "shell.execute_reply.started": "2025-04-12T18:50:01.521587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 18:50:10.528217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744483810.978906      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744483811.118389      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "import torch\n",
    "# Load the config and set num_labels=3\n",
    "config = AutoConfig.from_pretrained(\n",
    "    '/kaggle/input/checkpoint-4554',\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "# Load model with the modified config and ignore mismatches\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    '/kaggle/input/checkpoint-4554',\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True  # this tells Transformers to ignore the old classification head\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Check where the model is\n",
    "print(\"Model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:35.571749Z",
     "iopub.status.busy": "2025-04-12T18:50:35.570956Z",
     "iopub.status.idle": "2025-04-12T18:50:38.136710Z",
     "shell.execute_reply": "2025-04-12T18:50:38.136182Z",
     "shell.execute_reply.started": "2025-04-12T18:50:35.571721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=10,              # number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",     # evaluation strategy to adopt during training\n",
    "    save_strategy=\"epoch\",           # save checkpoint every epoch\n",
    "    report_to=\"all\",  # Show both console and progress bar\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    disable_tqdm=False  # Ensure progress bars are visible\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the model to train\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:51.647703Z",
     "iopub.status.busy": "2025-04-12T18:50:51.647410Z",
     "iopub.status.idle": "2025-04-12T19:37:01.473710Z",
     "shell.execute_reply": "2025-04-12T19:37:01.473073Z",
     "shell.execute_reply.started": "2025-04-12T18:50:51.647681Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7030' max='7030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7030/7030 46:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.819200</td>\n",
       "      <td>0.812374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>0.715568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.739749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.935292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>1.110428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>1.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>1.689890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>1.925538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>2.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>2.056302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7030, training_loss=0.2738979932725076, metrics={'train_runtime': 2769.4232, 'train_samples_per_second': 81.14, 'train_steps_per_second': 2.538, 'total_flos': 1342668323550720.0, 'train_loss': 0.2738979932725076, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:25:41.443307Z",
     "iopub.status.busy": "2025-04-13T09:25:41.443060Z",
     "iopub.status.idle": "2025-04-13T09:25:42.967211Z",
     "shell.execute_reply": "2025-04-13T09:25:42.966419Z",
     "shell.execute_reply.started": "2025-04-13T09:25:41.443290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"/kaggle/input/final-tuning/model fine tuned on review 1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"callmesan/indic-bert-roman-urdu-fine-grained\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:25:57.132798Z",
     "iopub.status.busy": "2025-04-13T09:25:57.132154Z",
     "iopub.status.idle": "2025-04-13T09:25:57.352237Z",
     "shell.execute_reply": "2025-04-13T09:25:57.351313Z",
     "shell.execute_reply.started": "2025-04-13T09:25:57.132773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:26:03.705223Z",
     "iopub.status.busy": "2025-04-13T09:26:03.704911Z",
     "iopub.status.idle": "2025-04-13T09:26:03.714031Z",
     "shell.execute_reply": "2025-04-13T09:26:03.713146Z",
     "shell.execute_reply.started": "2025-04-13T09:26:03.705193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'LABEL_0': 'Negative',\n",
    "    'LABEL_1': 'Neutral',\n",
    "    'LABEL_2': 'Positive'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:49:45.440487Z",
     "iopub.status.busy": "2025-04-13T09:49:45.440210Z",
     "iopub.status.idle": "2025-04-13T09:49:45.491188Z",
     "shell.execute_reply": "2025-04-13T09:49:45.490558Z",
     "shell.execute_reply.started": "2025-04-13T09:49:45.440467Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: tum bohat ache ho\n",
      "Predicted Sentiment: Positive (0.94)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"tum bohat ache ho\"\n",
    "result = classifier(text)[0]\n",
    "label_name = label_map[result['label']]\n",
    "score = result['score']\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Predicted Sentiment: {label_name} ({score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7112873,
     "sourceId": 11363970,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7120033,
     "sourceId": 11373294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7120311,
     "sourceId": 11373652,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7125067,
     "sourceId": 11379760,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7129560,
     "sourceId": 11385788,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
